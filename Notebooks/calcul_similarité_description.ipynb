{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd80d62",
   "metadata": {
    "id": "9fd80d62",
    "tags": []
   },
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67d55eca",
   "metadata": {
    "id": "67d55eca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install google-colab\n",
    "# !pip install nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17322502",
   "metadata": {
    "executionInfo": {
     "elapsed": 2428,
     "status": "ok",
     "timestamp": 1699466018451,
     "user": {
      "displayName": "Romain MARLET",
      "userId": "18112648248908016912"
     },
     "user_tz": -60
    },
    "id": "17322502",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d624e5a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2848,
     "status": "ok",
     "timestamp": 1699466021297,
     "user": {
      "displayName": "Romain MARLET",
      "userId": "18112648248908016912"
     },
     "user_tz": -60
    },
    "id": "d624e5a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../Data/companies_description.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "\n",
    "condition = (data['companyName'].isna()) | (data['description'].isna() | data['country'].isna())\n",
    "index_to_drop = data[condition].index\n",
    "data = data.drop(index_to_drop)\n",
    "\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "37e283e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1699423852860,
     "user": {
      "displayName": "mohamed didi",
      "userId": "12459858373354554760"
     },
     "user_tz": -60
    },
    "id": "37e283e5",
    "outputId": "197958d1-e81f-4e52-91d9-4418a5701e5c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>exchange</th>\n",
       "      <th>industry</th>\n",
       "      <th>website</th>\n",
       "      <th>description</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>https://usa.visa.com</td>\n",
       "      <td>Visa Inc. operates as a payments technology co...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Roadhouse, Inc.</td>\n",
       "      <td>NASDAQ Global Select</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>https://www.texasroadhouse.com</td>\n",
       "      <td>Texas Roadhouse, Inc., together with its subsi...</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamb Weston Holdings, Inc.</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>https://www.lambweston.com</td>\n",
       "      <td>Lamb Weston Holdings, Inc. produces, distribut...</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intact Financial Corporation</td>\n",
       "      <td>Toronto Stock Exchange</td>\n",
       "      <td>Insurance—Property &amp; Casualty</td>\n",
       "      <td>https://www.intactfc.com</td>\n",
       "      <td>Intact Financial Corporation, through its subs...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>NASDAQ Global Select</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>https://www.opko.com</td>\n",
       "      <td>OPKO Health, Inc., a healthcare company, engag...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37579</th>\n",
       "      <td>Relativity Acquisition Corp.</td>\n",
       "      <td>NASDAQ Global Market</td>\n",
       "      <td>Shell Companies</td>\n",
       "      <td>https://www.relativityacquisitions.com</td>\n",
       "      <td>Relativity Acquisition Corp. does not have sig...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37580</th>\n",
       "      <td>Prima Industrie SpA</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>https://www.primaindustrie.com</td>\n",
       "      <td>Prima Industrie SpA develops, manufactures, an...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37581</th>\n",
       "      <td>PT Putra Rajawali Kencana Tbk</td>\n",
       "      <td>Jakarta Stock Exchange</td>\n",
       "      <td>Trucking</td>\n",
       "      <td>https://puratrans.com</td>\n",
       "      <td>PT Putra Rajawali Kencana Tbk engages in the t...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37582</th>\n",
       "      <td>Agritek Holdings, Inc.</td>\n",
       "      <td>Other OTC</td>\n",
       "      <td>Real Estate Services</td>\n",
       "      <td>https://www.agritekholdings.com</td>\n",
       "      <td>Agritek Holdings, Inc. distributes hemp and ca...</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37583</th>\n",
       "      <td>Viewtran Group, Inc.</td>\n",
       "      <td>Other OTC</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>https://www.viewtran.com</td>\n",
       "      <td>Viewtran Group, Inc. provides supply chain fin...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37584 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         companyName                 exchange  \\\n",
       "0                          Visa Inc.  New York Stock Exchange   \n",
       "1              Texas Roadhouse, Inc.     NASDAQ Global Select   \n",
       "2         Lamb Weston Holdings, Inc.  New York Stock Exchange   \n",
       "3       Intact Financial Corporation   Toronto Stock Exchange   \n",
       "4                  OPKO Health, Inc.     NASDAQ Global Select   \n",
       "...                              ...                      ...   \n",
       "37579   Relativity Acquisition Corp.     NASDAQ Global Market   \n",
       "37580            Prima Industrie SpA                    Milan   \n",
       "37581  PT Putra Rajawali Kencana Tbk   Jakarta Stock Exchange   \n",
       "37582         Agritek Holdings, Inc.                Other OTC   \n",
       "37583           Viewtran Group, Inc.                Other OTC   \n",
       "\n",
       "                             industry                                 website  \\\n",
       "0                     Credit Services                    https://usa.visa.com   \n",
       "1                         Restaurants          https://www.texasroadhouse.com   \n",
       "2                      Packaged Foods              https://www.lambweston.com   \n",
       "3       Insurance—Property & Casualty                https://www.intactfc.com   \n",
       "4              Diagnostics & Research                    https://www.opko.com   \n",
       "...                               ...                                     ...   \n",
       "37579                 Shell Companies  https://www.relativityacquisitions.com   \n",
       "37580  Specialty Industrial Machinery          https://www.primaindustrie.com   \n",
       "37581                        Trucking                   https://puratrans.com   \n",
       "37582            Real Estate Services         https://www.agritekholdings.com   \n",
       "37583                 Credit Services                https://www.viewtran.com   \n",
       "\n",
       "                                             description              sector  \\\n",
       "0      Visa Inc. operates as a payments technology co...  Financial Services   \n",
       "1      Texas Roadhouse, Inc., together with its subsi...   Consumer Cyclical   \n",
       "2      Lamb Weston Holdings, Inc. produces, distribut...  Consumer Defensive   \n",
       "3      Intact Financial Corporation, through its subs...  Financial Services   \n",
       "4      OPKO Health, Inc., a healthcare company, engag...          Healthcare   \n",
       "...                                                  ...                 ...   \n",
       "37579  Relativity Acquisition Corp. does not have sig...  Financial Services   \n",
       "37580  Prima Industrie SpA develops, manufactures, an...         Industrials   \n",
       "37581  PT Putra Rajawali Kencana Tbk engages in the t...         Industrials   \n",
       "37582  Agritek Holdings, Inc. distributes hemp and ca...         Real Estate   \n",
       "37583  Viewtran Group, Inc. provides supply chain fin...  Financial Services   \n",
       "\n",
       "      country  \n",
       "0          US  \n",
       "1          US  \n",
       "2          US  \n",
       "3          CA  \n",
       "4          US  \n",
       "...       ...  \n",
       "37579      US  \n",
       "37580      IT  \n",
       "37581      ID  \n",
       "37582      US  \n",
       "37583      CN  \n",
       "\n",
       "[37584 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e715718",
   "metadata": {
    "id": "4e715718",
    "tags": []
   },
   "source": [
    "# Tokenization : plus besoin de le run, car le fichier data_tokenized.csv est créé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff103b4",
   "metadata": {
    "id": "0ff103b4",
    "tags": []
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344bef3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1699423853614,
     "user": {
      "displayName": "mohamed didi",
      "userId": "12459858373354554760"
     },
     "user_tz": -60
    },
    "id": "344bef3d",
    "outputId": "35908f87-391b-400d-edb7-b25a93a7519d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cff6ea9",
   "metadata": {
    "id": "8cff6ea9"
   },
   "outputs": [],
   "source": [
    "# desc0 = data['description'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "94544e8c",
   "metadata": {
    "id": "94544e8c"
   },
   "outputs": [],
   "source": [
    "# sentences = sent_tokenize(desc0)\n",
    "# words = word_tokenize(desc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84b33eb7",
   "metadata": {
    "id": "84b33eb7"
   },
   "outputs": [],
   "source": [
    "# [wrd.lower() for wrd in words if wrd.lower() not in stopwords.words('english') and wrd not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obk0bW9LiwN6",
   "metadata": {
    "id": "obk0bW9LiwN6"
   },
   "source": [
    "(avec stemming) temps d'execution pour 37 000 entreprises : 13 minutes\n",
    "(sans stemming) temps d'execution pour 37 000 entreprises : 11 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c912e41-4110-4088-bfa4-47a8ed42924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = nltk.stem.SnowballStemmer('english')\n",
    "# pstemmer = nltk.stem.PorterStemmer()\n",
    "# lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "# lemma.lemmatize('walking')\n",
    "# stemmer.stem('walking')\n",
    "# opko, health, inc., healthcare, company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67aad03b",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "67aad03b",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\Notebooks\\calcul_similarité_description.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m filtered_words\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# data = data.iloc[:100]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess_description)\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\Notebooks\\calcul_similarité_description.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m words \u001b[39m=\u001b[39m word_tokenize(description)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m stem:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   filtered_words \u001b[39m=\u001b[39m [stemmer\u001b[39m.\u001b[39mstem(word\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   filtered_words \u001b[39m=\u001b[39m [word\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation]\n",
      "\u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\Notebooks\\calcul_similarité_description.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m words \u001b[39m=\u001b[39m word_tokenize(description)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m stem:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   filtered_words \u001b[39m=\u001b[39m [stemmer\u001b[39m.\u001b[39mstem(word\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mand\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Moham/Documents/peer_analysis/PeerAnalysis/Notebooks/calcul_similarit%C3%A9_description.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   filtered_words \u001b[39m=\u001b[39m [word\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation]\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mjoin(file)\u001b[39m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m FileSystemPathPointer(_path)\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decorator\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[39m=\u001b[39m (args[\u001b[39m0\u001b[39m], add_py3_data(args[\u001b[39m1\u001b[39m])) \u001b[39m+\u001b[39m args[\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m init_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Moham\\Documents\\peer_analysis\\PeerAnalysis\\.venv\\lib\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[39m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexists(_path):\n\u001b[0;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file or directory: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m _path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "def preprocess_description(description, stem=True):\n",
    "  words = word_tokenize(description)\n",
    "  if stem:\n",
    "    filtered_words = [stemmer.stem(word.lower()) for word in words if word.lower() not in stopwords.words('english') and word not in string.punctuation]\n",
    "  else:\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stopwords.words('english') and word not in string.punctuation]\n",
    "\n",
    "  return filtered_words\n",
    "\n",
    "# data = data.iloc[:100]\n",
    "data['description'] = data['description'].apply(preprocess_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31744d6e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "31744d6e",
    "outputId": "604e8211-5b71-4731-946f-cccbc707c2aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>exchange</th>\n",
       "      <th>industry</th>\n",
       "      <th>website</th>\n",
       "      <th>description</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>https://usa.visa.com</td>\n",
       "      <td>[visa, inc., oper, payment, technolog, compani...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Roadhouse, Inc.</td>\n",
       "      <td>NASDAQ Global Select</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>https://www.texasroadhouse.com</td>\n",
       "      <td>[texa, roadhous, inc., togeth, subsidiari, ope...</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamb Weston Holdings, Inc.</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>https://www.lambweston.com</td>\n",
       "      <td>[lamb, weston, hold, inc., produc, distribut, ...</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intact Financial Corporation</td>\n",
       "      <td>Toronto Stock Exchange</td>\n",
       "      <td>Insurance—Property &amp; Casualty</td>\n",
       "      <td>https://www.intactfc.com</td>\n",
       "      <td>[intact, financi, corpor, subsidiari, provid, ...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>NASDAQ Global Select</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>https://www.opko.com</td>\n",
       "      <td>[opko, health, inc., healthcar, compani, engag...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    companyName                 exchange  \\\n",
       "0                     Visa Inc.  New York Stock Exchange   \n",
       "1         Texas Roadhouse, Inc.     NASDAQ Global Select   \n",
       "2    Lamb Weston Holdings, Inc.  New York Stock Exchange   \n",
       "3  Intact Financial Corporation   Toronto Stock Exchange   \n",
       "4             OPKO Health, Inc.     NASDAQ Global Select   \n",
       "\n",
       "                        industry                         website  \\\n",
       "0                Credit Services            https://usa.visa.com   \n",
       "1                    Restaurants  https://www.texasroadhouse.com   \n",
       "2                 Packaged Foods      https://www.lambweston.com   \n",
       "3  Insurance—Property & Casualty        https://www.intactfc.com   \n",
       "4         Diagnostics & Research            https://www.opko.com   \n",
       "\n",
       "                                         description              sector  \\\n",
       "0  [visa, inc., oper, payment, technolog, compani...  Financial Services   \n",
       "1  [texa, roadhous, inc., togeth, subsidiari, ope...   Consumer Cyclical   \n",
       "2  [lamb, weston, hold, inc., produc, distribut, ...  Consumer Defensive   \n",
       "3  [intact, financi, corpor, subsidiari, provid, ...  Financial Services   \n",
       "4  [opko, health, inc., healthcar, compani, engag...          Healthcare   \n",
       "\n",
       "  country  \n",
       "0      US  \n",
       "1      US  \n",
       "2      US  \n",
       "3      CA  \n",
       "4      US  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-UMearMcBrSG",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-UMearMcBrSG",
    "outputId": "5aa782b1-f028-4588-aa37-ca4f9f61631d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.iloc[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8e5ed",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "86e8e5ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"../Data/data_tokenized.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fMU4MuGPCEu7",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fMU4MuGPCEu7"
   },
   "outputs": [],
   "source": [
    "old_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed037e6",
   "metadata": {
    "id": "1ed037e6",
    "tags": []
   },
   "source": [
    "# Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hhz-BRR3wd8v",
   "metadata": {
    "id": "Hhz-BRR3wd8v"
   },
   "source": [
    "temps d'exe pour 37000 : 8 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff64182",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0ff64182",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_preprocess_data_tokenized():\n",
    "    data = pd.read_csv(\"../Data/data_tokenized.csv\")\n",
    "    data = data.drop(columns='Unnamed: 0')\n",
    "    data['description'] = data['description'].apply(eval)  # pour reconvertir la string en list\n",
    "    # data['country'] = data['country'].apply(eval)  # pour reconvertir la string en list\n",
    "    data = data.drop_duplicates('companyName')\n",
    "    data['description'] = data.apply(lambda row: row['description'] + [row['country'], row['sector']], axis=1)\n",
    "    data = data.drop(columns=['exchange', 'website'])\n",
    "    data['country'] = data['country'].replace({'GB':'UK',\n",
    "                                               'TW':'CN',\n",
    "                                               'GG':'FR',\n",
    "                                               'RE':'FR',\n",
    "                                               'GF':'FR',\n",
    "                                               'MQ':'UK',\n",
    "                                               'JE':'UK',\n",
    "                                               'AI':'UK',\n",
    "                                               'AN':'NL',\n",
    "                                               'GI':'UK'})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328f56e6-6b20-43cf-a2ca-5f62a23b15f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>industry</th>\n",
       "      <th>description</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>[visa, inc., operates, payments, technology, c...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Roadhouse, Inc.</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>[texas, roadhouse, inc., together, subsidiarie...</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamb Weston Holdings, Inc.</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>[lamb, weston, holdings, inc., produces, distr...</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intact Financial Corporation</td>\n",
       "      <td>Insurance—Property &amp; Casualty</td>\n",
       "      <td>[intact, financial, corporation, subsidiaries,...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>[opko, health, inc., healthcare, company, enga...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37577</th>\n",
       "      <td>Global Brokerage, Inc.</td>\n",
       "      <td>Financial Data &amp; Stock Exchanges</td>\n",
       "      <td>[global, brokerage, inc., subsidiaries, provid...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37580</th>\n",
       "      <td>Prima Industrie SpA</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>[prima, industrie, spa, develops, manufactures...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37581</th>\n",
       "      <td>PT Putra Rajawali Kencana Tbk</td>\n",
       "      <td>Trucking</td>\n",
       "      <td>[pt, putra, rajawali, kencana, tbk, engages, t...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37582</th>\n",
       "      <td>Agritek Holdings, Inc.</td>\n",
       "      <td>Real Estate Services</td>\n",
       "      <td>[agritek, holdings, inc., distributes, hemp, c...</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37583</th>\n",
       "      <td>Viewtran Group, Inc.</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>[viewtran, group, inc., provides, supply, chai...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         companyName                          industry  \\\n",
       "0                          Visa Inc.                   Credit Services   \n",
       "1              Texas Roadhouse, Inc.                       Restaurants   \n",
       "2         Lamb Weston Holdings, Inc.                    Packaged Foods   \n",
       "3       Intact Financial Corporation     Insurance—Property & Casualty   \n",
       "4                  OPKO Health, Inc.            Diagnostics & Research   \n",
       "...                              ...                               ...   \n",
       "37577         Global Brokerage, Inc.  Financial Data & Stock Exchanges   \n",
       "37580            Prima Industrie SpA    Specialty Industrial Machinery   \n",
       "37581  PT Putra Rajawali Kencana Tbk                          Trucking   \n",
       "37582         Agritek Holdings, Inc.              Real Estate Services   \n",
       "37583           Viewtran Group, Inc.                   Credit Services   \n",
       "\n",
       "                                             description              sector  \\\n",
       "0      [visa, inc., operates, payments, technology, c...  Financial Services   \n",
       "1      [texas, roadhouse, inc., together, subsidiarie...   Consumer Cyclical   \n",
       "2      [lamb, weston, holdings, inc., produces, distr...  Consumer Defensive   \n",
       "3      [intact, financial, corporation, subsidiaries,...  Financial Services   \n",
       "4      [opko, health, inc., healthcare, company, enga...          Healthcare   \n",
       "...                                                  ...                 ...   \n",
       "37577  [global, brokerage, inc., subsidiaries, provid...  Financial Services   \n",
       "37580  [prima, industrie, spa, develops, manufactures...         Industrials   \n",
       "37581  [pt, putra, rajawali, kencana, tbk, engages, t...         Industrials   \n",
       "37582  [agritek, holdings, inc., distributes, hemp, c...         Real Estate   \n",
       "37583  [viewtran, group, inc., provides, supply, chai...  Financial Services   \n",
       "\n",
       "      country  \n",
       "0          US  \n",
       "1          US  \n",
       "2          US  \n",
       "3          CA  \n",
       "4          US  \n",
       "...       ...  \n",
       "37577      US  \n",
       "37580      IT  \n",
       "37581      ID  \n",
       "37582      US  \n",
       "37583      CN  \n",
       "\n",
       "[31149 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_preprocess_data_tokenized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OfPVdRiBqKEq",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OfPVdRiBqKEq"
   },
   "outputs": [],
   "source": [
    "# data['description'] = data['description'].apply(lambda x: [token for token in x if not token.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UMmYgubXuLMI",
   "metadata": {
    "id": "UMmYgubXuLMI"
   },
   "source": [
    "Temps d'execution pour 37 000 entreprises : 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0YOC1ie_a-xa",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0YOC1ie_a-xa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def build_tfidf(df):\n",
    "  tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "  tfidf_matrix = tfidf_vectorizer.fit_transform(df['description'].astype(str))\n",
    "\n",
    "  list(tfidf_matrix)\n",
    "  # print(pd.Series(tfidf_matrix.toarray()))\n",
    "  sparse.save_npz(\"../Data/tfidf_matrix.npz\", tfidf_matrix)\n",
    "\n",
    "  df['vec_tfidf'] = list(tfidf_matrix)\n",
    "  # data['vec_tfidf']=tfidf_matrix.toarray()\n",
    "\n",
    "  # feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95942d99-b697-4830-a008-33fe346b0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_preprocess_data_tokenized()\n",
    "data = build_tfidf(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aXJVBdzdN72D",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aXJVBdzdN72D",
    "outputId": "3bb9c20c-a767-4aac-9a45-c1b8807b224b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data['vec_tfidf'].iloc[0].toarray()\n",
    "# Assuming tfidf_matrix is your TF-IDF sparse matrix\n",
    "print(data['vec_tfidf'].iloc[0].toarray())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ii2QIzMojDIM",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ii2QIzMojDIM"
   },
   "outputs": [],
   "source": [
    "# data['vec_tfidf'].values[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7645b8e",
   "metadata": {
    "id": "f7645b8e",
    "tags": []
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59dcdb08",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "59dcdb08",
    "outputId": "8a46241d-47c3-4ec2-a3df-dbb18eebb554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['visa',\n",
       " 'inc.',\n",
       " 'operates',\n",
       " 'payments',\n",
       " 'technology',\n",
       " 'company',\n",
       " 'worldwide',\n",
       " 'company',\n",
       " 'facilitates',\n",
       " 'digital',\n",
       " 'payments',\n",
       " 'among',\n",
       " 'consumers',\n",
       " 'merchants',\n",
       " 'financial',\n",
       " 'institutions',\n",
       " 'businesses',\n",
       " 'strategic',\n",
       " 'partners',\n",
       " 'government',\n",
       " 'entities',\n",
       " 'operates',\n",
       " 'visanet',\n",
       " 'transaction',\n",
       " 'processing',\n",
       " 'network',\n",
       " 'enables',\n",
       " 'authorization',\n",
       " 'clearing',\n",
       " 'settlement',\n",
       " 'payment',\n",
       " 'transactions',\n",
       " 'addition',\n",
       " 'company',\n",
       " 'offers',\n",
       " 'card',\n",
       " 'products',\n",
       " 'platforms',\n",
       " 'value-added',\n",
       " 'services',\n",
       " 'provides',\n",
       " 'services',\n",
       " 'visa',\n",
       " 'visa',\n",
       " 'electron',\n",
       " 'interlink',\n",
       " 'vpay',\n",
       " 'plus',\n",
       " 'brands',\n",
       " 'visa',\n",
       " 'inc.',\n",
       " 'strategic',\n",
       " 'agreement',\n",
       " 'ooredoo',\n",
       " 'provide',\n",
       " 'enhanced',\n",
       " 'payment',\n",
       " 'experience',\n",
       " 'visa',\n",
       " 'cardholders',\n",
       " 'ooredoo',\n",
       " 'customers',\n",
       " 'qatar',\n",
       " 'visa',\n",
       " 'inc.',\n",
       " 'founded',\n",
       " '1958',\n",
       " 'headquartered',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'california',\n",
       " 'US',\n",
       " 'Financial Services']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc0 = data['description'][0]\n",
    "desc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "XZamDdwOlFMd",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XZamDdwOlFMd",
    "outputId": "43ed7d7b-f2e0-4e9b-b0eb-48b38248ed8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.7% 28.9/1662.8MB downloaded"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Chargez le modèle Word2Vec\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\downloader.py:496\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    494\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_dir, file_name)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder_dir):\n\u001b[1;32m--> 496\u001b[0m     _download(name)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_path:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\downloader.py:396\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    394\u001b[0m fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{fname}\u001b[39;00m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    395\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_dir, fname)\n\u001b[1;32m--> 396\u001b[0m urllib\u001b[38;5;241m.\u001b[39murlretrieve(url_data, dst_path, reporthook\u001b[38;5;241m=\u001b[39m_progress)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _calculate_md5_checksum(dst_path) \u001b[38;5;241m==\u001b[39m _get_checksum(name):\n\u001b[0;32m    398\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:274\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    273\u001b[0m read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[1;32m--> 274\u001b[0m tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n\u001b[0;32m    275\u001b[0m blocknum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from gensim.downloader import load\n",
    "\n",
    "model = load('word2vec-google-news-300')\n",
    "\n",
    "path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "\n",
    "# Chargez le modèle Word2Vec\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "#model = Word2Vec.load(path)\n",
    "\n",
    "def calculate_average_word2vec(tokens, model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in model:  # Directly check in the model\n",
    "            nwords += 1\n",
    "            feature_vector = np.add(feature_vector, model[token])  # Directly access the vector\n",
    "\n",
    "    if nwords > 0:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "data['description_word2vec'] = data['description'].apply(\n",
    "    lambda x: calculate_average_word2vec(x, model, num_features=300)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kSO3YdhejtkM",
   "metadata": {
    "id": "kSO3YdhejtkM",
    "tags": []
   },
   "source": [
    "# Calcul de distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bk_DphEWW_1",
   "metadata": {
    "id": "3bk_DphEWW_1",
    "tags": []
   },
   "source": [
    "### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-ewWAsCxyqx4",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-ewWAsCxyqx4"
   },
   "outputs": [],
   "source": [
    "# data.loc[data['companyName'] == 'Visa Inc.']['vec_tfidf'].iloc[0].toarray()\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54laA5gupfne",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "54laA5gupfne",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return norm(vec1 - vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NCwYS4c5uVPC",
   "metadata": {
    "id": "NCwYS4c5uVPC"
   },
   "source": [
    "Temps d'execution pour 37 000 entreprises : plante car la RAM est insuffisante (13 gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "_AHkd2SWyEIg",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_AHkd2SWyEIg",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Cosine Similarity:\n",
      "                               companyName  Similarity\n",
      "18055  BLS International Services Limited    0.415832\n",
      "1077                            Mogo Inc.    0.311937\n",
      "4973                           Adyen N.V.    0.292689\n",
      "916               Mastercard Incorporated    0.292129\n",
      "5910                           Usio, Inc.    0.268081\n",
      "13926                            XTM Inc.    0.261167\n",
      "1153               AppTech Payments Corp.    0.247371\n",
      "15013                       Isracard Ltd.    0.245550\n",
      "11669                   Plexian AB (publ)    0.244023\n",
      "1553                  ACI Worldwide, Inc.    0.231816\n",
      "\n",
      "Word2Vec Cosine Similarity:\n",
      "                      companyName  Similarity\n",
      "916      Mastercard Incorporated    0.901665\n",
      "1077                   Mogo Inc.    0.900398\n",
      "5910                  Usio, Inc.    0.889770\n",
      "28560  GMO Payment Gateway, Inc.    0.889736\n",
      "2600               EVERTEC, Inc.    0.889080\n",
      "1975                Fiserv, Inc.    0.886142\n",
      "887           i3 Verticals, Inc.    0.885526\n",
      "3064               PaySign, Inc.    0.882738\n",
      "37370                Wirecard AG    0.880923\n",
      "472      Euronet Worldwide, Inc.    0.879726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "\n",
    "def find_similar_companies(target_company, df, vector_column='vec_tfidf', n=5, method='tfidf', metric='cosine'):\n",
    "    # Ensure the target company exists in the DataFrame\n",
    "    if target_company not in df['companyName'].values:\n",
    "        print(\"Vérifier le nom de l'entreprise.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get the vector of the target company\n",
    "    target_vector = df.loc[df['companyName'] == target_company, vector_column].iloc[0]\n",
    "\n",
    "    # For TF-IDF, convert sparse matrix to dense array if needed\n",
    "    if method == 'tfidf' and hasattr(target_vector, \"toarray\"):\n",
    "        target_vector = target_vector.toarray()[0]\n",
    "        df = df.copy()  # Avoid modifying the original DataFrame\n",
    "        df[vector_column] = df[vector_column].apply(lambda x: x.toarray()[0] if hasattr(x, \"toarray\") else x)\n",
    "\n",
    "    # Compute similarities or distances\n",
    "    if metric == 'cosine':\n",
    "        similarities = cosine_similarity([target_vector], list(df[vector_column]))\n",
    "        similarity_column = 'Similarity'\n",
    "        scores = similarities[0]\n",
    "    elif metric == 'euclidean':\n",
    "        distances = euclidean_distances([target_vector], list(df[vector_column]))\n",
    "        similarity_column = 'Distance'\n",
    "        scores = distances.flatten()\n",
    "        scores = 1 / (0.0001 + scores)  # Inverting distances to make them similar to similarity scores\n",
    "\n",
    "    # Create a DataFrame for similar companies\n",
    "    similar_companies = pd.DataFrame({'companyName': df['companyName'], similarity_column: scores})\n",
    "    sort_ascending = True if metric == 'euclidean' else False\n",
    "    similar_companies = similar_companies.sort_values(by=similarity_column, ascending=sort_ascending)\n",
    "\n",
    "    # Exclude the target company from the results\n",
    "    similar_companies = similar_companies[similar_companies['companyName'] != target_company]\n",
    "\n",
    "    return similar_companies.head(n)\n",
    "\n",
    "# Example usage\n",
    "result_tfidf_cosine = find_similar_companies(\"Visa Inc.\", data, 'vec_tfidf', n=10, method='tfidf', metric='cosine')\n",
    "result_tfidf_euclidean = find_similar_companies(\"Visa Inc.\", data, 'vec_tfidf', n=10, method='tfidf', metric='euclidean')\n",
    "\n",
    "result_word2vec_cosine = find_similar_companies(\"Visa Inc.\", data, 'description_word2vec', n=10, method='word2vec', metric='cosine')\n",
    "result_word2vec_euclidean = find_similar_companies(\"Visa Inc.\", data, 'description_word2vec', n=10, method='word2vec', metric='euclidean')\n",
    "\n",
    "print(\"TF-IDF Cosine Similarity:\\n\", result_tfidf_cosine)\n",
    "\n",
    "print(\"\\nWord2Vec Cosine Similarity:\\n\", result_word2vec_cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed04540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Cosine Similarity:\n",
      "                               companyName  Similarity\n",
      "18055  BLS International Services Limited    0.415832\n",
      "1077                            Mogo Inc.    0.311937\n",
      "4973                           Adyen N.V.    0.292689\n",
      "916               Mastercard Incorporated    0.292129\n",
      "5910                           Usio, Inc.    0.268081\n",
      "13926                            XTM Inc.    0.261167\n",
      "1153               AppTech Payments Corp.    0.247371\n",
      "15013                       Isracard Ltd.    0.245550\n",
      "11669                   Plexian AB (publ)    0.244023\n",
      "1553                  ACI Worldwide, Inc.    0.231816\n",
      "\n",
      "Word2Vec Cosine Similarity:\n",
      "                      companyName  Similarity\n",
      "916      Mastercard Incorporated    0.901665\n",
      "1077                   Mogo Inc.    0.900398\n",
      "5910                  Usio, Inc.    0.889770\n",
      "28560  GMO Payment Gateway, Inc.    0.889736\n",
      "2600               EVERTEC, Inc.    0.889080\n",
      "1975                Fiserv, Inc.    0.886142\n",
      "887           i3 Verticals, Inc.    0.885526\n",
      "3064               PaySign, Inc.    0.882738\n",
      "37370                Wirecard AG    0.880923\n",
      "472      Euronet Worldwide, Inc.    0.879726\n"
     ]
    }
   ],
   "source": [
    "result_tfidf_cosine = find_similar_companies(\"Visa Inc.\", data, 'vec_tfidf', n=10, method='tfidf', metric='cosine')\n",
    "\n",
    "result_word2vec_cosine = find_similar_companies(\"Visa Inc.\", data, 'description_word2vec', n=10, method='word2vec', metric='cosine')\n",
    "\n",
    "print(\"TF-IDF Cosine Similarity:\\n\", result_tfidf_cosine)\n",
    "\n",
    "print(\"\\nWord2Vec Cosine Similarity:\\n\", result_word2vec_cosine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3afab12",
   "metadata": {},
   "source": [
    "## Performance tests Using GPT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ed722",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eec04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = {\n",
    "    \"Visa Inc.\": [\n",
    "        \"Mastercard Incorporated\", \"American Express Company\", \"PayPal Holdings, Inc.\",\n",
    "        \"JPMorgan Chase & Co.\", \"Citigroup Inc.\", \"Goldman Sachs Group, Inc.\",\n",
    "        \"Morgan Stanley\", \"Bank of America Corporation\", \"Wells Fargo & Company\",\n",
    "        \"U.S. Bancorp\"],\n",
    "    \"Texas Roadhouse, Inc.\": [\n",
    "        \"McDonald’s Corp.\", \"Yum! Brands, Inc.\", \"Chipotle Mexican Grill, Inc.\",\n",
    "        \"Starbucks Corporation\", \"Domino's Pizza, Inc.\", \"Burger King\", \n",
    "        \"Denny's Corporation\", \"Wendy's Company\", \"Papa John's International, Inc.\", \n",
    "        \"Jack in the Box Inc.\"],\n",
    "    \"Lamb Weston Holdings, Inc.\": [\n",
    "        \"Kraft Heinz Company\", \"Tyson Foods, Inc.\", \"Hormel Foods Corporation\",\n",
    "        \"Sysco Corporation\", \"PepsiCo, Inc.\", \"Conagra Brands, Inc.\", \"Kellogg Company\",\n",
    "        \"General Mills, Inc.\", \"Campbell Soup Company\", \"The Hershey Company\"],\n",
    "    \"Intact Financial Corporation\": [\n",
    "        \"MetLife, Inc.\", \"Prudential Financial, Inc.\", \"The Travelers Companies, Inc.\",\n",
    "        \"Allstate Corporation\", \"American International Group, Inc.\", \"Progressive Corporation\",\n",
    "        \"State Farm Insurance\", \"Liberty Mutual Insurance Company\", \"Chubb Limited\",\n",
    "        \"Zurich Insurance Group\"],\n",
    "    \"OPKO Health, Inc.\": [\n",
    "        \"Pfizer Inc.\", \"Johnson & Johnson\", \"Merck & Co., Inc.\", \"Gilead Sciences, Inc.\",\n",
    "        \"Amgen Inc.\", \"AbbVie Inc.\", \"Bristol Myers Squibb Company\", \"Sanofi\", \n",
    "        \"GlaxoSmithKline plc\", \"Novartis AG\"],\n",
    "    \"Ferroglobe PLC\": [\n",
    "        \"BHP Group\", \"Rio Tinto Group\", \"Vale S.A.\", \"Glencore plc\", \"Anglo American plc\",\n",
    "        \"Freeport-McMoRan Inc.\", \"Alcoa Corporation\", \"ArcelorMittal\", \"Teck Resources Limited\",\n",
    "        \"Nucor Corporation\"],\n",
    "    \"Hanesbrands Inc.\": [\n",
    "        \"Levi Strauss & Co.\", \"PVH Corp.\", \"Ralph Lauren Corporation\", \"Gap Inc.\",\n",
    "        \"L Brands, Inc.\", \"Under Armour, Inc.\", \"VF Corporation\", \"Columbia Sportswear Company\",\n",
    "        \"American Eagle Outfitters, Inc.\", \"Nordstrom, Inc.\"],\n",
    "    \"Esports Entertainment Group, Inc.\": [\n",
    "        \"Activision Blizzard, Inc.\", \"Electronic Arts Inc.\", \"Take-Two Interactive Software, Inc.\",\n",
    "        \"Zynga Inc.\", \"Ubisoft Entertainment SA\", \"Square Enix Holdings Co., Ltd.\",\n",
    "        \"Bandai Namco Holdings Inc.\", \"Tencent Holdings Limited\", \"SEGA Sammy Holdings Inc.\",\n",
    "        \"Capcom Co., Ltd.\"],\n",
    "    \"WW International, Inc.\": [\n",
    "        \"Nutrisystem, Inc.\", \"Medifast, Inc.\", \"Herbalife Nutrition Ltd.\", \"Planet Fitness, Inc.\",\n",
    "        \"Peloton Interactive, Inc.\", \"Nautilus, Inc.\", \"Fitbit, Inc.\", \"Lululemon Athletica Inc.\",\n",
    "        \"Nike, Inc.\", \"Under Armour, Inc.\"],\n",
    "    \"CommScope Holding Company, Inc.\": [\n",
    "        \"Cisco Systems, Inc.\", \"Qualcomm Incorporated\", \"Nokia Corporation\", \"Ericsson\",\n",
    "        \"ZTE Corporation\", \"Huawei Technologies Co., Ltd.\", \"Juniper Networks, Inc.\",\n",
    "        \"Motorola Solutions, Inc.\", \"Corning Incorporated\", \"Broadcom Inc.\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6e43bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test and score the algorithm\n",
    "def test_algorithm(df, test_cases):\n",
    "    scores = {}  # Dictionary to hold scores for each method and metric\n",
    "\n",
    "    for company in test_cases.keys():\n",
    "        # Run the function for different methods and metrics\n",
    "        results = {\n",
    "            'tfidf_cosine': find_similar_companies(company, df, 'vec_tfidf', 10, 'tfidf', 'cosine'),\n",
    "            'word2vec_cosine': find_similar_companies(company, df, 'description_word2vec', 10, 'word2vec', 'cosine'),\n",
    "        }\n",
    "\n",
    "        # Scoring each result\n",
    "        for key, result in results.items():\n",
    "            output_companies = list(result['companyName'])\n",
    "            expected_companies = test_cases[company]\n",
    "            score = 0\n",
    "\n",
    "            for idx, expected_company in enumerate(expected_companies):\n",
    "                if expected_company in output_companies:\n",
    "                    output_idx = output_companies.index(expected_company)\n",
    "                    score += 10 - abs(idx - output_idx)\n",
    "                else:\n",
    "                    score += 0  # Company not found, score 0\n",
    "\n",
    "            scores.setdefault(key, 0)\n",
    "            scores[key] += score\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4fb3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf_cosine': 48, 'word2vec_cosine': 61}\n"
     ]
    }
   ],
   "source": [
    "# Run the test and print scores\n",
    "scores = test_algorithm(data, test_cases)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51b119e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Expected Company         TF-IDF Cosine Similarity  \\\n",
      "0            Cisco Systems, Inc.               Casa Systems, Inc.   \n",
      "1          Qualcomm Incorporated                      Belden Inc.   \n",
      "2              Nokia Corporation  Arcadyan Technology Corporation   \n",
      "3                       Ericsson       Cogeco Communications Inc.   \n",
      "4                ZTE Corporation    Liberty Broadband Corporation   \n",
      "5  Huawei Technologies Co., Ltd.            SITI Networks Limited   \n",
      "6         Juniper Networks, Inc.                 Altice USA, Inc.   \n",
      "7       Motorola Solutions, Inc.     Ortel Communications Limited   \n",
      "8           Corning Incorporated             Vecima Networks Inc.   \n",
      "9                  Broadcom Inc.        CyberTAN Technology, Inc.   \n",
      "\n",
      "                  Word2Vec Cosine Similarity  TF-IDF Score  Word2Vec Score  \n",
      "0               Cambium Networks Corporation             0               0  \n",
      "1                      ADTRAN Holdings, Inc.             0               0  \n",
      "2                EDIMAX Technology Co., Ltd.             0               0  \n",
      "3                              Ubiquiti Inc.             0               0  \n",
      "4                         Casa Systems, Inc.             0               0  \n",
      "5                                Belden Inc.             0               0  \n",
      "6              Gilat Satellite Networks Ltd.             0               0  \n",
      "7  Loop Telecommunication International,Inc.             0               0  \n",
      "8                            MaxLinear, Inc.             0               0  \n",
      "9                     Tejas Networks Limited             0               0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "company_target =  \"CommScope Holding Company, Inc.\"\n",
    "# Assuming you have the results from your function\n",
    "result_tfidf_cosine = find_similar_companies(company_target, data, 'vec_tfidf', n=10, method='tfidf', metric='cosine')\n",
    "result_word2vec_cosine = find_similar_companies(company_target, data, 'description_word2vec', n=10, method='word2vec', metric='cosine')\n",
    "\n",
    "# Extracting company names from the results\n",
    "tfidf_cosine_companies = list(result_tfidf_cosine['companyName'])\n",
    "word2vec_cosine_companies = list(result_word2vec_cosine['companyName'])\n",
    "\n",
    "# Test cases for \"Visa Inc.\"\n",
    "expected_companies = test_cases[company_target]\n",
    "\n",
    "# Creating a DataFrame to display the results\n",
    "df = pd.DataFrame({\n",
    "    \"Expected Company\": expected_companies,\n",
    "    \"TF-IDF Cosine Similarity\": tfidf_cosine_companies,\n",
    "    \"Word2Vec Cosine Similarity\": word2vec_cosine_companies\n",
    "})\n",
    "\n",
    "# Function to calculate score\n",
    "def calculate_score(expected, actual, actual_list):\n",
    "    if actual in expected:\n",
    "        expected_position = expected.index(actual)\n",
    "        actual_position = actual_list.index(actual)\n",
    "        position_difference = abs(expected_position - actual_position)\n",
    "        return max(10 - position_difference, 0)\n",
    "    return 0\n",
    "\n",
    "# Adding scores to the DataFrame\n",
    "df[\"TF-IDF Score\"] = df.apply(lambda row: calculate_score(expected_companies, row[\"TF-IDF Cosine Similarity\"], tfidf_cosine_companies), axis=1)\n",
    "df[\"Word2Vec Score\"] = df.apply(lambda row: calculate_score(expected_companies, row[\"Word2Vec Cosine Similarity\"], word2vec_cosine_companies), axis=1)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xptIW6vWZqCH",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xptIW6vWZqCH"
   },
   "outputs": [],
   "source": [
    "# def from_token_to_ranking(name=\"Visa Inc.\"):\n",
    "#   \"\"\"\n",
    "#   fonction de test uniquement, il ne faut pas load le csv comme cela, car il y a des traitements à faire dessus.\n",
    "#   \"\"\"\n",
    "\n",
    "#   df = pd.read_csv(\"/content/drive/MyDrive/S9/DDEFI/Projet_DDEFI/code/data_tokenized.csv\")\n",
    "#   df.drop(columns='Unnamed: 0', inplace=True)\n",
    "#   df=df.iloc[:10]\n",
    "\n",
    "#   df = build_tfidf(df)\n",
    "\n",
    "#   result_tfidf = find_similar_companies(name, df, 'vec_tfidf', n=20)\n",
    "#   return result_tfidf\n",
    "\n",
    "# # from_token_to_ranking(\"Visa Inc.\")\n",
    "# from_token_to_ranking(\"Texas Roadhouse, Inc.\")\n",
    "# #from_token_to_ranking(\"Lamb Weston Holdings, Inc.\")\n",
    "# #from_token_to_ranking(\"Ferroglobe PLC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35io1WD2O9n3",
   "metadata": {
    "id": "35io1WD2O9n3",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GPD per Capita bis (world bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HupvWEW6t5lB",
   "metadata": {
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1699466236664,
     "user": {
      "displayName": "Romain MARLET",
      "userId": "18112648248908016912"
     },
     "user_tz": -60
    },
    "id": "HupvWEW6t5lB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_mapping_name_abb = {\n",
    "    'Aruba': 'AW',\n",
    "    'Afghanistan': 'AF',\n",
    "    'Angola': 'AO',\n",
    "    'Albania': 'AL',\n",
    "    'Andorra': 'AD',\n",
    "    'United Arab Emirates': 'AE',\n",
    "    'Argentina': 'AR',\n",
    "    'Armenia': 'AM',\n",
    "    'American Samoa': 'AS',\n",
    "    'Antigua and Barbuda': 'AG',\n",
    "    'Australia': 'AU',\n",
    "    'Austria': 'AT',\n",
    "    'Azerbaijan': 'AZ',\n",
    "    'Burundi': 'BI',\n",
    "    'Belgium': 'BE',\n",
    "    'Benin': 'BJ',\n",
    "    'Burkina Faso': 'BF',\n",
    "    'Bangladesh': 'BD',\n",
    "    'Bulgaria': 'BG',\n",
    "    'Bahrain': 'BH',\n",
    "    'Bahamas, The': 'BS',\n",
    "    'Bosnia and Herzegovina': 'BA',\n",
    "    'Belarus': 'BY',\n",
    "    'Belize': 'BZ',\n",
    "    'Bermuda': 'BM',\n",
    "    'Bolivia': 'BO',\n",
    "    'Brazil': 'BR',\n",
    "    'Barbados': 'BB',\n",
    "    'Brunei Darussalam': 'BN',\n",
    "    'Bhutan': 'BT',\n",
    "    'Botswana': 'BW',\n",
    "    'Central African Republic': 'CF',\n",
    "    'Canada': 'CA',\n",
    "    'Switzerland': 'CH',\n",
    "    'Channel Islands': 'XK',\n",
    "    'Chile': 'CL',\n",
    "    'China': 'CN',\n",
    "    \"Cote d'Ivoire\": 'CI',\n",
    "    'Cameroon': 'CM',\n",
    "    'Congo, Dem. Rep.': 'CD',\n",
    "    'Congo, Rep.': 'CG',\n",
    "    'Colombia': 'CO',\n",
    "    'Comoros': 'KM',\n",
    "    'Cabo Verde': 'CV',\n",
    "    'Costa Rica': 'CR',\n",
    "    'Cuba': 'CU',\n",
    "    'Curacao': 'CW',\n",
    "    'Cayman Islands': 'KY',\n",
    "    'Cyprus': 'CY',\n",
    "    'Czechia': 'CZ',\n",
    "    'Germany': 'DE',\n",
    "    'Djibouti': 'DJ',\n",
    "    'Dominica': 'DM',\n",
    "    'Denmark': 'DK',\n",
    "    'Dominican Republic': 'DO',\n",
    "    'Algeria': 'DZ',\n",
    "    'Ecuador': 'EC',\n",
    "    'Egypt, Arab Rep.': 'EG',\n",
    "    'Eritrea': 'ER',\n",
    "    'Spain': 'ES',\n",
    "    'Estonia': 'EE',\n",
    "    'Ethiopia': 'ET',\n",
    "    'Finland': 'FI',\n",
    "    'Fiji': 'FJ',\n",
    "    'France': 'FR',\n",
    "    'Faroe Islands': 'FO',\n",
    "    'Micronesia, Fed. Sts.': 'FM',\n",
    "    'Gabon': 'GA',\n",
    "    'United Kingdom': 'UK',\n",
    "    'Georgia': 'GE',\n",
    "    'Ghana': 'GH',\n",
    "    'Gibraltar': 'GI',\n",
    "    'Guinea': 'GN',\n",
    "    'Gambia, The': 'GM',\n",
    "    'Guinea-Bissau': 'GW',\n",
    "    'Equatorial Guinea': 'GQ',\n",
    "    'Greece': 'GR',\n",
    "    'Grenada': 'GD',\n",
    "    'Greenland': 'GL',\n",
    "    'Guatemala': 'GT',\n",
    "    'Guam': 'GU',\n",
    "    'Guyana': 'GY',\n",
    "    'Hong Kong SAR, China': 'HK',\n",
    "    'Honduras': 'HN',\n",
    "    'Croatia': 'HR',\n",
    "    'Haiti': 'HT',\n",
    "    'Hungary': 'HU',\n",
    "    'Indonesia': 'ID',\n",
    "    'Isle of Man': 'IM',\n",
    "    'India': 'IN',\n",
    "    'Ireland': 'IE',\n",
    "    'Iran, Islamic Rep.': 'IR',\n",
    "    'Iraq': 'IQ',\n",
    "    'Iceland': 'IS',\n",
    "    'Israel': 'IL',\n",
    "    'Italy': 'IT',\n",
    "    'Jamaica': 'JM',\n",
    "    'Jordan': 'JO',\n",
    "    'Japan': 'JP',\n",
    "    'Kazakhstan': 'KZ',\n",
    "    'Kenya': 'KE',\n",
    "    'Kyrgyz Republic': 'KG',\n",
    "    'Cambodia': 'KH',\n",
    "    'Kiribati': 'KI',\n",
    "    'St. Kitts and Nevis': 'KN',\n",
    "    'Korea, Rep.': 'KR',\n",
    "    'Kuwait': 'KW',\n",
    "    'Lao PDR': 'LA',\n",
    "    'Lebanon': 'LB',\n",
    "    'Liberia': 'LR',\n",
    "    'Libya': 'LY',\n",
    "    'St. Lucia': 'LC',\n",
    "    'Liechtenstein': 'LI',\n",
    "    'Sri Lanka': 'LK',\n",
    "    'Lesotho': 'LS',\n",
    "    'Lithuania': 'LT',\n",
    "    'Luxembourg': 'LU',\n",
    "    'Latvia': 'LV',\n",
    "    'Macao SAR, China': 'MO',\n",
    "    'St. Martin (French part)': 'MF',\n",
    "    'Morocco': 'MA',\n",
    "    'Monaco': 'MC',\n",
    "    'Moldova': 'MD',\n",
    "    'Madagascar': 'MG',\n",
    "    'Maldives': 'MV',\n",
    "    'Mexico': 'MX',\n",
    "    'Marshall Islands': 'MH',\n",
    "    'North Macedonia': 'MK',\n",
    "    'Mali': 'ML',\n",
    "    'Malta': 'MT',\n",
    "    'Myanmar': 'MM',\n",
    "    'Montenegro': 'ME',\n",
    "    'Mongolia': 'MN',\n",
    "    'Northern Mariana Islands': 'MP',\n",
    "    'Mozambique': 'MZ',\n",
    "    'Mauritania': 'MR',\n",
    "    'Mauritius': 'MU',\n",
    "    'Malawi': 'MW',\n",
    "    'Malaysia': 'MY',\n",
    "    'Namibia': 'NA',\n",
    "    'New Caledonia': 'NC',\n",
    "    'Niger': 'NE',\n",
    "    'Nigeria': 'NG',\n",
    "    'Nicaragua': 'NI',\n",
    "    'Netherlands': 'NL',\n",
    "    'Norway': 'NO',\n",
    "    'Nepal': 'NP',\n",
    "    'Nauru': 'NR',\n",
    "    'New Zealand': 'NZ',\n",
    "    'Oman': 'OM',\n",
    "    'Pakistan': 'PK',\n",
    "    'Panama': 'PA',\n",
    "    'Peru': 'PE',\n",
    "    'Philippines': 'PH',\n",
    "    'Palau': 'PW',\n",
    "    'Papua New Guinea': 'PG',\n",
    "    'Poland': 'PL',\n",
    "    'Puerto Rico': 'PR',\n",
    "    \"Korea, Dem. People's Rep.\": 'KP',\n",
    "    'Portugal': 'PT',\n",
    "    'Paraguay': 'PY',\n",
    "    'West Bank and Gaza': 'PS',\n",
    "    'French Polynesia': 'PF',\n",
    "    'Qatar': 'QA',\n",
    "    'Romania': 'RO',\n",
    "    'Russian Federation': 'RU',\n",
    "    'Rwanda': 'RW',\n",
    "    'Saudi Arabia': 'SA',\n",
    "    'Sudan': 'SD',\n",
    "    'Senegal': 'SN',\n",
    "    'Singapore': 'SG',\n",
    "    'Solomon Islands': 'SB',\n",
    "    'Sierra Leone': 'SL',\n",
    "    'El Salvador': 'SV',\n",
    "    'San Marino': 'SM',\n",
    "    'Somalia': 'SO',\n",
    "    'Serbia': 'RS',\n",
    "    'South Sudan': 'SS',\n",
    "    'Sao Tome and Principe': 'ST',\n",
    "    'Suriname': 'SR',\n",
    "    'Slovak Republic': 'SK',\n",
    "    'Slovenia': 'SI',\n",
    "    'Sweden': 'SE',\n",
    "    'Eswatini': 'SZ',\n",
    "    'Sint Maarten (Dutch part)': 'SX',\n",
    "    'Seychelles': 'SC',\n",
    "    'Syrian Arab Republic': 'SY',\n",
    "    'Turks and Caicos Islands': 'TC',\n",
    "    'Chad': 'TD',\n",
    "    'Togo': 'TG',\n",
    "    'Thailand': 'TH',\n",
    "    'Tajikistan': 'TJ',\n",
    "    'Turkmenistan': 'TM',\n",
    "    'Timor-Leste': 'TL',\n",
    "    'Tonga': 'TO',\n",
    "    'Trinidad and Tobago': 'TT',\n",
    "    'Tunisia': 'TN',\n",
    "    'Turkiye': 'TR',\n",
    "    'Tuvalu': 'TV',\n",
    "    'Tanzania': 'TZ',\n",
    "    'Uganda': 'UG',\n",
    "    'Ukraine': 'UA',\n",
    "    'Uruguay': 'UY',\n",
    "    'United States': 'US',\n",
    "    'Uzbekistan': 'UZ',\n",
    "    'St. Vincent and the Grenadines': 'VC',\n",
    "    'Venezuela, RB': 'VE',\n",
    "    'British Virgin Islands': 'VG',\n",
    "    'Virgin Islands (U.S.)': 'VI',\n",
    "    'Vietnam': 'VN',\n",
    "    'Vanuatu': 'VU',\n",
    "    'Samoa': 'WS',\n",
    "    'Kosovo': 'XK',\n",
    "    'Yemen, Rep.': 'YE',\n",
    "    'South Africa': 'ZA',\n",
    "    'Zambia': 'ZM',\n",
    "    'Zimbabwe': 'ZW'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ecff0-4dc3-4fa8-9e01-46ba96be9029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_GDP_similarity_matrix():\n",
    "    file_path = \"../Data/GDP per capita (current US$).csv\"\n",
    "    data_GDP = pd.read_csv(file_path)\n",
    "    data_GDP = data_GDP.rename(columns={'GDP per capita (current US$)':'GDPpc'})\n",
    "    data_GDP = data_GDP.drop(columns={'Economy Code', 'Year'})\n",
    "    data_GDP = data_GDP.drop(data_GDP[data_GDP['Economy'].isin(['Eritrea', \"Korea, Dem. People's Rep.\"])].index)\n",
    "    data_GDP['Economy'] = data_GDP['Economy'].map(dict_mapping_name_abb)\n",
    "    \n",
    "    gdp_array = data_GDP['GDPpc'].values\n",
    "    num_pays = len(gdp_array)\n",
    "    similarity_matrix = np.zeros((num_pays, num_pays))\n",
    "\n",
    "    for i in range(num_pays):\n",
    "        for j in range(num_pays):\n",
    "            distance = (np.abs(gdp_array[i] - gdp_array[j])) / (gdp_array[i]+gdp_array[j])\n",
    "            similarity_matrix[i][j] = 1/(1+distance)\n",
    "\n",
    "    similarity_matrix = pd.DataFrame(similarity_matrix, index=data_GDP['Economy'], columns=data_GDP['Economy'])\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "GDP_similarity_matrix = build_GDP_similarity_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962f483-a59e-41c0-89ec-cc7b4255619e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# liste de keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a429a7e-0944-44bf-a27e-d3d5b5feea10",
   "metadata": {},
   "source": [
    "- problème du stemming : on propose des stemming ou des tokens entiers ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "btoa-p-yUGk4",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "btoa-p-yUGk4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tokens = df_full['description'].explode().tolist() # Concaténation des listes de tokens\n",
    "unique_tokens = set(all_tokens) # Création du pool de tokens uniques\n",
    "token_counts = pd.Series(all_tokens).value_counts() # Calcul du dénombrement de chaque token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1530c807-d551-4ac0-a681-f1efd15822df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.56162316607275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tokens)/df_full.shape[0]  # il y a ne moyenne 85 mots par description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854d3df2-d6a2-40b8-bdc6-876553dd5a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.4085190535757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.quantile(0.9999)/df_full.shape[0]*100 # on ne prend que les mots qui apparaissent en moyenne moins de 56% du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31a85f37-e6f3-4481-9b84-c7bc08e91655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006420751870043982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.quantile(0.7)/df_full.shape[0]*100 # on ne prend que les mots qui apparaissent en moyenne plus de 0.08% du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510babe3-9d79-4d17-b70f-30f4ed19819a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_keywords = list(token_counts[\n",
    "    # (token_counts.quantile(0.7)<=token_counts)&\n",
    "    (token_counts<=token_counts.quantile(0.9999))\n",
    "].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xswyAzgOTjUZ",
   "metadata": {
    "id": "xswyAzgOTjUZ",
    "tags": []
   },
   "source": [
    "# filtrage par secteur et keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a2ece-5d9a-47f2-a31d-86152d717293",
   "metadata": {},
   "source": [
    "- Comment appliquer un stemming sur les keywords tout en proposant les mots en entier ?\n",
    "- problème de filtrage : diagram de Venn ET/OU ??\n",
    "- faire une liste de keyword en triant les tokens de descirption par fréquence d'apparition\n",
    "- une fois qu'on a fait la liste des keywords possibles à partir du dataframe, demander à chatgpt si les keywors peuvent aussi correspondre à d'autres entreprises (dans le cas ou une description est trop pauvre en mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b73a0b-2412-4c4a-94a0-a6a87ab0f0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESHOLD_SIZE_FINAL_GROUP=1000  # taille du groupe que l'on veut avoir pour commencer l'analyse avec les données financières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4eed158-c55d-45d0-a73b-aec87ecae2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_preprocess_data_tokenized()\n",
    "data = build_tfidf(data)\n",
    "df=data.copy()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8d2129-1f94-44a1-9e70-eeb1f0012a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5609e-4298-4ef7-b826-535f7930202b",
   "metadata": {},
   "source": [
    "## Filtrage secteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba01a61-f40f-42a4-99af-298fe570c314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>industry</th>\n",
       "      <th>description</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>vec_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>[visa, inc., oper, payment, technolog, compani...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 69507)\\t0.04329421873343035\\n  (0, 28536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Roadhouse, Inc.</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>[texa, roadhous, inc., togeth, subsidiari, ope...</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 20183)\\t0.06172506483002616\\n  (0, 18440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamb Weston Holdings, Inc.</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>[lamb, weston, hold, inc., produc, distribut, ...</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 21254)\\t0.06293066474975732\\n  (0, 24134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intact Financial Corporation</td>\n",
       "      <td>Insurance—Property &amp; Casualty</td>\n",
       "      <td>[intact, financi, corpor, subsidiari, provid, ...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CA</td>\n",
       "      <td>(0, 13404)\\t0.03851612061606596\\n  (0, 78417...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>[opko, health, inc., healthcar, compani, engag...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 34610)\\t0.03688475698854317\\n  (0, 29088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37577</th>\n",
       "      <td>Global Brokerage, Inc.</td>\n",
       "      <td>Financial Data &amp; Stock Exchanges</td>\n",
       "      <td>[global, brokerag, inc., subsidiari, provid, o...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 30460)\\t0.1793094610567329\\n  (0, 22281)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37580</th>\n",
       "      <td>Prima Industrie SpA</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>[prima, industri, spa, develop, manufactur, ma...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>IT</td>\n",
       "      <td>(0, 17803)\\t0.10854261371782986\\n  (0, 62937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37581</th>\n",
       "      <td>PT Putra Rajawali Kencana Tbk</td>\n",
       "      <td>Trucking</td>\n",
       "      <td>[pt, putra, rajawali, kencana, tbk, engag, tra...</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>ID</td>\n",
       "      <td>(0, 64075)\\t0.18442821739381648\\n  (0, 42205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37582</th>\n",
       "      <td>Agritek Holdings, Inc.</td>\n",
       "      <td>Real Estate Services</td>\n",
       "      <td>[agritek, hold, inc., distribut, hemp, cannabi...</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 49001)\\t0.1490741453938388\\n  (0, 34947)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37583</th>\n",
       "      <td>Viewtran Group, Inc.</td>\n",
       "      <td>Credit Services</td>\n",
       "      <td>[viewtran, group, inc., provid, suppli, chain,...</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>CN</td>\n",
       "      <td>(0, 17685)\\t0.24973667360982638\\n  (0, 82298...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31149 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         companyName                          industry  \\\n",
       "0                          Visa Inc.                   Credit Services   \n",
       "1              Texas Roadhouse, Inc.                       Restaurants   \n",
       "2         Lamb Weston Holdings, Inc.                    Packaged Foods   \n",
       "3       Intact Financial Corporation     Insurance—Property & Casualty   \n",
       "4                  OPKO Health, Inc.            Diagnostics & Research   \n",
       "...                              ...                               ...   \n",
       "37577         Global Brokerage, Inc.  Financial Data & Stock Exchanges   \n",
       "37580            Prima Industrie SpA    Specialty Industrial Machinery   \n",
       "37581  PT Putra Rajawali Kencana Tbk                          Trucking   \n",
       "37582         Agritek Holdings, Inc.              Real Estate Services   \n",
       "37583           Viewtran Group, Inc.                   Credit Services   \n",
       "\n",
       "                                             description              sector  \\\n",
       "0      [visa, inc., oper, payment, technolog, compani...  Financial Services   \n",
       "1      [texa, roadhous, inc., togeth, subsidiari, ope...   Consumer Cyclical   \n",
       "2      [lamb, weston, hold, inc., produc, distribut, ...  Consumer Defensive   \n",
       "3      [intact, financi, corpor, subsidiari, provid, ...  Financial Services   \n",
       "4      [opko, health, inc., healthcar, compani, engag...          Healthcare   \n",
       "...                                                  ...                 ...   \n",
       "37577  [global, brokerag, inc., subsidiari, provid, o...  Financial Services   \n",
       "37580  [prima, industri, spa, develop, manufactur, ma...         Industrials   \n",
       "37581  [pt, putra, rajawali, kencana, tbk, engag, tra...         Industrials   \n",
       "37582  [agritek, hold, inc., distribut, hemp, cannabi...         Real Estate   \n",
       "37583  [viewtran, group, inc., provid, suppli, chain,...  Financial Services   \n",
       "\n",
       "      country                                          vec_tfidf  \n",
       "0          US    (0, 69507)\\t0.04329421873343035\\n  (0, 28536...  \n",
       "1          US    (0, 20183)\\t0.06172506483002616\\n  (0, 18440...  \n",
       "2          US    (0, 21254)\\t0.06293066474975732\\n  (0, 24134...  \n",
       "3          CA    (0, 13404)\\t0.03851612061606596\\n  (0, 78417...  \n",
       "4          US    (0, 34610)\\t0.03688475698854317\\n  (0, 29088...  \n",
       "...       ...                                                ...  \n",
       "37577      US    (0, 30460)\\t0.1793094610567329\\n  (0, 22281)...  \n",
       "37580      IT    (0, 17803)\\t0.10854261371782986\\n  (0, 62937...  \n",
       "37581      ID    (0, 64075)\\t0.18442821739381648\\n  (0, 42205...  \n",
       "37582      US    (0, 49001)\\t0.1490741453938388\\n  (0, 34947)...  \n",
       "37583      CN    (0, 17685)\\t0.24973667360982638\\n  (0, 82298...  \n",
       "\n",
       "[31149 rows x 6 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8702830c-372a-4fad-be4f-dc35b1599f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "900a86d6-1fc1-4cd7-bbe7-834651f26b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_df_size(df, sector, list_keywords_raw): \n",
    "    \"\"\"\n",
    "    retourne df filtré qui contient 2 parties : \n",
    "        - les entreprises du même secteur\n",
    "        - les entreprises des autres secteurs qui contiennent tous les keywords (condition 'AND')\n",
    "        \n",
    "    list_keywords_raw : liste de keywords entrés par l'utilisateur. Ils ne sont pas nécessairement dans les tokens \n",
    "    du dataset --> on calcule leurs cousins sémantiques présents dans le datasets.\n",
    "    \"\"\"\n",
    "    list_keywords = build_semantic_from_raw_keywords(list_keywords_raw, df)\n",
    "    \n",
    "    \n",
    "    df = df.copy()\n",
    "    list_keywords = list_keywords.copy()\n",
    "    filtered_df = df[df.sector==sector] # on ajoute directement les entrerises du même secteur\n",
    "\n",
    "\n",
    "    # on ajoute les entreprises qui vérifient tous les keywords et qui font partie des autres secteurs\n",
    "    df_other_sectors = df.loc[df['sector'] != sector].copy()\n",
    "    \n",
    "    print('1', filtered_df.shape)\n",
    "\n",
    "    \n",
    "    \"ON COMMENCER PAR AUGMENTER LA ZONE DE RECHERCHE\"\n",
    "    # cmt=0\n",
    "    for keyword in list_keywords:\n",
    "        # cmt+=1\n",
    "        # print(cmt)\n",
    "        \n",
    "        \"on ajoute les entreprises des autres secteurs qui vérifient tous les keywords\"\n",
    "        filtered_df = pd.concat([filtered_df, filter_on_keyword(df_other_sectors, keyword)])\n",
    "\n",
    "    print('2', filtered_df.shape)\n",
    "    \n",
    "    \n",
    "    \"DESORMAIS ON DIMINUE LA ZONE DE RECHERCHE\" \n",
    "    solution1=False\n",
    "    if solution1:\n",
    "        # solution 1 : prend en compte l'importance relative de chaque keyword : les premiers sont les plus importants\n",
    "        while filtered_df.shape[0]>THRESHOLD_SIZE_FINAL_GROUP:\n",
    "            \"si le df est trop grand, on réduit la taille avec un filtrage conjonctif 'condition 'AND'\"\n",
    "            if len(list_keywords)==0:\n",
    "                \"on sort direct de la boucle, ce n'est pas optimal car la liste est encore trop grande\"\n",
    "                break\n",
    "\n",
    "                \"ou bien on peut demander à l'utilisateur d'ajouter de nouveaux keywords\"\n",
    "                # new_keyword = input(\n",
    "                #     \"Il n'y a pas assez de keyword pour réduire la zone de recherche (TAILLE ZONE = {}/TAILLE MAX = {}),\\\n",
    "                #     veuillez en ajouter un : \".format(filtered_df.shape[0], THRESHOLD_SIZE_FINAL_GROUP))\n",
    "                # list_keywords.append(new_keyword)\n",
    "            keyword = list_keywords.pop(0)\n",
    "            filtered_df = filter_on_keyword(filtered_df, keyword)\n",
    "\n",
    "        \n",
    "        \n",
    "    # solution 2 : ne prend pas en compte l'importance relative de chaque keyword\n",
    "    # nouvelle colonne qui va compter le nombre de keywords que contient chaque boite\n",
    "\n",
    "    filtered_df['nombre_keywords'] = filtered_df['description'].apply(\n",
    "        lambda x: sum(keyword in x for keyword in list_keywords)\n",
    "        )\n",
    "    filtered_df = filtered_df.sort_values(by='nombre_keywords', ascending=False)\n",
    "    filtered_df = filtered_df.head(THRESHOLD_SIZE_FINAL_GROUP)\n",
    "    \n",
    "    \n",
    "        \n",
    "    print('3', filtered_df.shape)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "\n",
    "def filter_on_keyword(df, keyword):\n",
    "    resultat = df[df['description'].apply(lambda x: keyword in x)]\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ec9b3-5c25-4ffe-9a5c-e86ede064990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_semantic_from_raw_keywords(df, list_keywords_raw):\n",
    "    \"\"\"\n",
    "    retourne la liste des cousins sémantiques des keywords de list_keywords_raw présents dans df\n",
    "    \"\"\"\n",
    "    THRESHOLD_SEMANTIC = 0.5 # on prend les cousins sémantiques dont la similarité est supérieure à THRESHOLD_SEMANTIC\n",
    "    THRESHOLD_QUANTILE = 0.9999 # on ne considère que les mots dont la fréquence d'apparition est dans THRESHOLD_QUANTILE\n",
    "    \n",
    "    \"construction de la liste de tous les cousins potentiels\"\n",
    "    all_tokens = df['description'].explode().tolist() # Concaténation des listes de tokens\n",
    "    unique_tokens = set(all_tokens) # Création du pool de tokens uniques\n",
    "    token_counts = pd.Series(all_tokens).value_counts() # Calcul du dénombrement de chaque token\n",
    "    \n",
    "    list_tokens = list(token_counts[\n",
    "        # (token_counts.quantile(0.7)<=token_counts)&\n",
    "        (token_counts<=token_counts.quantile(THRESHOLD_QUANTILE))\n",
    "        ].index)\n",
    "    \n",
    "    \n",
    "    model = load_w2v_model(list_tokens)\n",
    "    \n",
    "    list_keywords_semantic = find_semantic_cousins(list_keywords_raw, list_tokens, model, THRESHOLD_SEMANTIC)\n",
    "    \n",
    "    return list_keywords_semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79bce0-ff2a-4610-926b-4e3a25e8b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v_model(list_training_tokens):\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b5b0a-c731-4609-9f3c-e503391fc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_semantic_cousins(list_keywords_raw, token_list, model, threshold_similarity):\n",
    "    try:\n",
    "        # Obtenez les vecteurs de tous les tokens\n",
    "        token_vectors = [model.wv[token] for token in token_list]\n",
    "\n",
    "        all_semantic_cousins = []\n",
    "\n",
    "        for keyword in list_keywords_raw:\n",
    "            try:\n",
    "                # Obtenez le vecteur du mot clé\n",
    "                keyword_vector = model.wv[keyword]\n",
    "\n",
    "                # cosine similarity entre le mot clé et tous les tokens\n",
    "                similarities = cosine_similarity([keyword_vector], token_vectors)[0]\n",
    "\n",
    "                # Récupérez les indices des tokens dont la similarité dépasse le seuil\n",
    "                selected_indices = [i for i, sim in enumerate(similarities) if sim > threshold_similarity]\n",
    "\n",
    "                # Ajoutez les tokens correspondant aux indices sélectionnés à la liste\n",
    "                all_semantic_cousins.extend(token_list[i] for i in selected_indices)\n",
    "\n",
    "            except KeyError:\n",
    "                # Gère le cas où le mot clé n'est pas dans le vocabulaire du modèle\n",
    "                pass\n",
    "\n",
    "        # Créez un ensemble à partir de la liste pour obtenir des cousins uniques\n",
    "        unique_cousins = set(all_semantic_cousins)\n",
    "\n",
    "        return list(unique_cousins)\n",
    "\n",
    "    except KeyError:\n",
    "        # Gère le cas où aucun token n'est pas dans le vocabulaire du modèle\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation avec seuil de similarité\n",
    "result = find_semantic_cousins(list_keywords_raw, list_tokens, model, threshold_similarity=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e9d7f-186c-4320-97eb-79a599df8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_semantic_cousins()\n",
    "list_keywords_raw = ['apple', 'car']\n",
    "list_tokens = ['fruit', 'vehicle', 'banana', 'grape', 'bus', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c479ad-6c27-42b7-bf26-d1ef5d60125d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Financial Services', 'Consumer Cyclical', 'Consumer Defensive',\n",
       "       'Healthcare', 'Basic Materials', 'Technology', 'Energy',\n",
       "       'Utilities', 'Industrials', 'Communication Services',\n",
       "       'Real Estate', nan], dtype=object)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.sector.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca748212-856e-4fff-b44c-5f60376cb6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (5293, 6)\n",
      "2 (7356, 6)\n",
      "3 (640, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>industry</th>\n",
       "      <th>description</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>vec_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Xcel Energy Inc.</td>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "      <td>[xcel, energi, inc., subsidiari, generat, purc...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 4756)\\t0.08087261915490325\\n  (0, 2949)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PG&amp;E Corporation</td>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "      <td>[pg, e, corpor, subsidiari, pacif, gas, electr...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 37)\\t0.11394246445711267\\n  (0, 339)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>American Electric Power Company, Inc.</td>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "      <td>[american, electr, power, compani, inc., elect...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 1105)\\t0.15627613406178759\\n  (0, 38)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Emera Incorporated</td>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "      <td>[emera, incorpor, energi, servic, compani, sub...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>CA</td>\n",
       "      <td>(0, 323)\\t0.0915135471077655\\n  (0, 227)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Brookfield Renewable Corporation</td>\n",
       "      <td>Utilities—Renewable</td>\n",
       "      <td>[brookfield, renew, corpor, own, oper, portfol...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 1100)\\t0.23165880192615612\\n  (0, 798)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37347</th>\n",
       "      <td>PETRONAS Gas Berhad</td>\n",
       "      <td>Utilities—Regulated Gas</td>\n",
       "      <td>[petrona, gas, berhad, oper, gas, infrastructu...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>MY</td>\n",
       "      <td>(0, 733)\\t0.06532786736756555\\n  (0, 3758)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37423</th>\n",
       "      <td>New Energy Solar Limited</td>\n",
       "      <td>Utilities—Renewable</td>\n",
       "      <td>[new, energi, solar, limit, acquir, own, manag...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>AU</td>\n",
       "      <td>(0, 538)\\t0.10777822145067113\\n  (0, 3963)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37448</th>\n",
       "      <td>PT. Terregra Asia Energy Tbk</td>\n",
       "      <td>Utilities—Renewable</td>\n",
       "      <td>[pt, terregra, asia, energi, tbk, focus, devel...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>ID</td>\n",
       "      <td>(0, 3387)\\t0.19680971731084454\\n  (0, 2962)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501</th>\n",
       "      <td>Volt Power Group Limited</td>\n",
       "      <td>Utilities—Renewable</td>\n",
       "      <td>[volt, power, group, limit, togeth, subsidiari...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>AU</td>\n",
       "      <td>(0, 928)\\t0.16440343450066308\\n  (0, 2671)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37561</th>\n",
       "      <td>U.S. Wind Farming, Inc.</td>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "      <td>[u.s., wind, farm, inc., oper, renew, energi, ...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>US</td>\n",
       "      <td>(0, 1783)\\t0.32810024727521553\\n  (0, 1782)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 companyName                      industry  \\\n",
       "18                          Xcel Energy Inc.  Utilities—Regulated Electric   \n",
       "45                          PG&E Corporation  Utilities—Regulated Electric   \n",
       "59     American Electric Power Company, Inc.  Utilities—Regulated Electric   \n",
       "61                        Emera Incorporated  Utilities—Regulated Electric   \n",
       "67          Brookfield Renewable Corporation           Utilities—Renewable   \n",
       "...                                      ...                           ...   \n",
       "37347                    PETRONAS Gas Berhad       Utilities—Regulated Gas   \n",
       "37423               New Energy Solar Limited           Utilities—Renewable   \n",
       "37448           PT. Terregra Asia Energy Tbk           Utilities—Renewable   \n",
       "37501               Volt Power Group Limited           Utilities—Renewable   \n",
       "37561                U.S. Wind Farming, Inc.  Utilities—Regulated Electric   \n",
       "\n",
       "                                             description     sector country  \\\n",
       "18     [xcel, energi, inc., subsidiari, generat, purc...  Utilities      US   \n",
       "45     [pg, e, corpor, subsidiari, pacif, gas, electr...  Utilities      US   \n",
       "59     [american, electr, power, compani, inc., elect...  Utilities      US   \n",
       "61     [emera, incorpor, energi, servic, compani, sub...  Utilities      CA   \n",
       "67     [brookfield, renew, corpor, own, oper, portfol...  Utilities      US   \n",
       "...                                                  ...        ...     ...   \n",
       "37347  [petrona, gas, berhad, oper, gas, infrastructu...  Utilities      MY   \n",
       "37423  [new, energi, solar, limit, acquir, own, manag...  Utilities      AU   \n",
       "37448  [pt, terregra, asia, energi, tbk, focus, devel...  Utilities      ID   \n",
       "37501  [volt, power, group, limit, togeth, subsidiari...  Utilities      AU   \n",
       "37561  [u.s., wind, farm, inc., oper, renew, energi, ...  Utilities      US   \n",
       "\n",
       "                                               vec_tfidf  \n",
       "18       (0, 4756)\\t0.08087261915490325\\n  (0, 2949)\\...  \n",
       "45       (0, 37)\\t0.11394246445711267\\n  (0, 339)\\t0....  \n",
       "59       (0, 1105)\\t0.15627613406178759\\n  (0, 38)\\t0...  \n",
       "61       (0, 323)\\t0.0915135471077655\\n  (0, 227)\\t0....  \n",
       "67       (0, 1100)\\t0.23165880192615612\\n  (0, 798)\\t...  \n",
       "...                                                  ...  \n",
       "37347    (0, 733)\\t0.06532786736756555\\n  (0, 3758)\\t...  \n",
       "37423    (0, 538)\\t0.10777822145067113\\n  (0, 3963)\\t...  \n",
       "37448    (0, 3387)\\t0.19680971731084454\\n  (0, 2962)\\...  \n",
       "37501    (0, 928)\\t0.16440343450066308\\n  (0, 2671)\\t...  \n",
       "37561    (0, 1783)\\t0.32810024727521553\\n  (0, 1782)\\...  \n",
       "\n",
       "[640 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# test_list_keyword = random.sample(list_keywords, 15)\n",
    "# test_list_keyword = [\n",
    "#     # 'company', \n",
    "#                    # 'inc.', 'product',\n",
    "#                     'produces', \n",
    "#                    'healthcare'\n",
    "#                   ]\n",
    "\n",
    "test_list_keyword = ['Utilities', 'Communication Services']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_sector = 'Industrials'\n",
    "\n",
    "filtered_df = reduce_df_size(df_full, sector=test_sector, list_keywords=test_list_keyword)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-6olhrGlCfcK",
   "metadata": {
    "id": "-6olhrGlCfcK",
    "tags": []
   },
   "source": [
    "# Join description and GDP similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QfuzVvQPCk5D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "error",
     "timestamp": 1699466369813,
     "user": {
      "displayName": "Romain MARLET",
      "userId": "18112648248908016912"
     },
     "user_tz": -60
    },
    "id": "QfuzVvQPCk5D",
    "outputId": "1b5f7896-c372-4dee-f830-ab554b4c4c84",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_preprocess_data_tokenized()\n",
    "data = build_tfidf(data)\n",
    "df=data.copy()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3a2cb-c931-4713-8bd3-346fb1f5918e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e6f6b-f8dc-404b-b815-28ae96f56e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar_companies(target_company, df, vector_column='vec_tfidf', n=5, similarity='cosine'):\n",
    "    df=df.copy()\n",
    "    df[vector_column] = df[vector_column].apply(lambda x: x.toarray()[0])\n",
    "    target_vector = df.loc[df['companyName'] == target_company][vector_column]\n",
    "\n",
    "    if target_vector.shape[0]>0:\n",
    "        target_vector = target_vector.iloc[0]\n",
    "    else:\n",
    "        print(\"Vérifier le nom de l'entreprise.\")\n",
    "        return -1\n",
    "\n",
    "    if similarity == 'cosine':\n",
    "        similarities = cosine_similarity([target_vector], list(df[vector_column]))\n",
    "\n",
    "        similar_companies = pd.DataFrame({'companyName': df['companyName'], 'Similarity': similarities[0], 'country': df['country']})\n",
    "        similar_companies = similar_companies.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "    return similar_companies\n",
    "\n",
    "# find_similar_companies(target_company = 'Visa Inc.', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J6PnykKJG1yA",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J6PnykKJG1yA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ranking_similarity = find_similar_companies('Visa Inc.', df)\n",
    "# display(ranking_similarity)\n",
    "\n",
    "def build_similarity_GDP_column(ranking_similarity_description):\n",
    "    \n",
    "    ranking_similarity = ranking_similarity_description.copy()\n",
    "                    \n",
    "    GDP_similarity_matrix = build_GDP_similarity_matrix()\n",
    "    dict_similarity_GDP = {}\n",
    "\n",
    "    for index, row in ranking_similarity.iterrows():\n",
    "        entreprise_similaire = row['companyName']\n",
    "        pays_entreprise_similaire = row['country']\n",
    "        distance_GDP = GDP_similarity_matrix.loc[ranking_similarity.iloc[0]['country'], pays_entreprise_similaire]  # le pays cible est : ranking_similarity.iloc[0]['country']\n",
    "        dict_similarity_GDP[entreprise_similaire] = distance_GDP\n",
    "\n",
    "    ranking_similarity['similarity_GDP'] = [dict_similarity_GDP[entreprise] for entreprise in ranking_similarity['companyName']]\n",
    "    ranking_similarity.drop(columns=['country'], inplace=True)\n",
    "\n",
    "    return ranking_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4yOrpYGBOArm",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4yOrpYGBOArm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_similarities(ranking_similarity, beta=0.5):\n",
    "    df=ranking_similarity.copy()\n",
    "    df['Similarity'] = (1/(1+beta))*(df['Similarity']+beta*df['similarity_GDP'])\n",
    "    df = df.drop(columns={'similarity_GDP'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f555a7-0c15-493b-a1d9-a462501b6825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_similarity(df, target_name='Visa Inc.'):\n",
    "    df = df.copy()\n",
    "    ranking_similarity_description = find_similar_companies(target_name, df)\n",
    "    ranking_similarity_description_and_GDP = build_similarity_GDP_column(ranking_similarity_description)\n",
    "    return combine_similarities(ranking_similarity_description_and_GDP, beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a543f-4bea-40ef-9253-6c297cf3d031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xcel Energy Inc.'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.iloc[0].companyName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc7b83-24ce-465b-a51a-eaa7e561a61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyName</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Xcel Energy Inc.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Black Hills Corporation</td>\n",
       "      <td>0.679636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>CenterPoint Energy, Inc.</td>\n",
       "      <td>0.663868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Duke Energy Corporation</td>\n",
       "      <td>0.662362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Exelon Corporation</td>\n",
       "      <td>0.661961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14433</th>\n",
       "      <td>Agripower France SA</td>\n",
       "      <td>0.266533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>Dlaboratory Sweden AB (publ)</td>\n",
       "      <td>0.299005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10717</th>\n",
       "      <td>Ekopak NV</td>\n",
       "      <td>0.284765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>Companhia de Saneamento de Minas Gerais</td>\n",
       "      <td>0.193931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26170</th>\n",
       "      <td>Jiangxi Hongcheng Environment Co.,Ltd.</td>\n",
       "      <td>0.200198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   companyName  Similarity\n",
       "18                            Xcel Energy Inc.    1.000000\n",
       "1211                   Black Hills Corporation    0.679636\n",
       "2407                  CenterPoint Energy, Inc.    0.663868\n",
       "746                    Duke Energy Corporation    0.662362\n",
       "960                         Exelon Corporation    0.661961\n",
       "...                                        ...         ...\n",
       "14433                      Agripower France SA    0.266533\n",
       "17290             Dlaboratory Sweden AB (publ)    0.299005\n",
       "10717                                Ekopak NV    0.284765\n",
       "5006   Companhia de Saneamento de Minas Gerais    0.193931\n",
       "26170   Jiangxi Hongcheng Environment Co.,Ltd.    0.200198\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_similarity(filtered_df, target_name='Xcel Energy Inc.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "325ada93",
    "f7645b8e"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
